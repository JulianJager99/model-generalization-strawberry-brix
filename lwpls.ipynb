{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### _Setup_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset memory\n",
        "%reset -f"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479290221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from typing import List, Union, Tuple\n",
        "from scipy.spatial.distance import pdist, squareform, cdist\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from kneed import KneeLocator\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479307164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "df = pd.read_csv('data.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479337361
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Functions_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_col_index_of_spectra(\n",
        "    df: pd.DataFrame\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Find the column index where spectral data starts.\n",
        "\n",
        "    Assumes spectral column names can be converted to float (e.g., \"730.5\", \"731.0\").\n",
        "\n",
        "    Parameters:\n",
        "        df : Input DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Index of the first spectral column, or -1 if not found.\n",
        "    \"\"\"\n",
        "    for idx, col in enumerate(df.columns):\n",
        "        try:\n",
        "            float(col)\n",
        "            return idx\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "    return -1\n",
        "\n",
        "def split_train_test(\n",
        "    df: pd.DataFrame,\n",
        "    test_variety: str,\n",
        "    test_season: int       \n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into one training set and two test sets:\n",
        "\n",
        "    - Variety test set: Variety == test_variety AND Year == 2024\n",
        "    - Season test set : Year == test_season \n",
        "\n",
        "    The training set excludes all rows that belong to any of the test sets.\n",
        "    The season test set only includes varieties that are present in the training set.\n",
        "\n",
        "    Parameters:\n",
        "        df           : Full pandas DataFrame\n",
        "        test_variety : Variety used for the test set\n",
        "        test_season  : Year used for the season test\n",
        "\n",
        "    Returns:\n",
        "        df_train        : Training set\n",
        "        df_test_variety : Test set for specified variety and 2024\n",
        "        df_test_season  : Test set for specified season (filtered by train varieties)\n",
        "    \"\"\"\n",
        "\n",
        "    # Select test set for the specified variety in year 2024\n",
        "    df_test_variety = df[\n",
        "        (df[\"Variety\"] == test_variety) &\n",
        "        (df[\"Scan Date Year\"] == 2024)\n",
        "    ]\n",
        "\n",
        "    # Select test set for the specified season (regardless of variety)\n",
        "    df_test_season = df[\n",
        "        df[\"Scan Date Year\"] == test_season\n",
        "    ]\n",
        "\n",
        "    # Select training set (exclude test variety and test season)\n",
        "    df_train = df[\n",
        "        (df[\"Variety\"] != test_variety) &\n",
        "        (df[\"Scan Date Year\"] != test_season)\n",
        "    ]\n",
        "\n",
        "    # Filter season test set to only include varieties present in training set\n",
        "    train_varieties = df_train[\"Variety\"].unique()\n",
        "    df_test_season = df_test_season[\n",
        "        df_test_season[\"Variety\"].isin(train_varieties)\n",
        "    ]\n",
        "\n",
        "    return df_train, df_test_variety, df_test_season\n",
        "\n",
        "def split_x_y(\n",
        "    df: pd.DataFrame,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Split train and test DataFrames into x (spectra features) and y (target) arrays.\n",
        "    Assumes find_col_index_of_spectra() is defined globally.\n",
        "\n",
        "    Parameters:\n",
        "        df_train: Training set DataFrame.\n",
        "        df_test : Test set DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        x_train: NumPy array of training features.\n",
        "        y_train: NumPy array of training targets.\n",
        "    \"\"\"\n",
        "    spectra_cols = list(df.columns[find_col_index_of_spectra(df):])\n",
        "    target_cols = ['Brix (Position)']\n",
        "\n",
        "    x = df[spectra_cols].values\n",
        "    y = df[target_cols].values\n",
        "\n",
        "    return (\n",
        "        x,\n",
        "        y\n",
        "    )\n",
        "\n",
        "def compute_distance_matrix(\n",
        "    matrix_one: np.ndarray,\n",
        "    matrix_two: np.ndarray,\n",
        "    metric: str = \"euclidean\"\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the pairwise distance matrix between two input matrices in float32.\n",
        "    Optimizes by only computing the upper triangle if both matrices are the same.\n",
        "\n",
        "    Parameters:\n",
        "        matrix_one : np.ndarray of shape (n_samples_one, n_features)\n",
        "        matrix_two : np.ndarray of shape (n_samples_two, n_features)\n",
        "        metric     : str, distance metric to use (default: 'euclidean')\n",
        "\n",
        "    Returns:\n",
        "        distance_matrix : np.ndarray of shape (n_samples_one, n_samples_two)\n",
        "    \"\"\"\n",
        "    # Convert inputs to float32 to reduce memory usage and improve speed\n",
        "    matrix_one = matrix_one.astype(np.float32)\n",
        "    matrix_two = matrix_two.astype(np.float32)\n",
        "\n",
        "    # If both matrices are the same (by reference or content), use symmetric distance matrix\n",
        "    if matrix_one is matrix_two or np.array_equal(matrix_one, matrix_two):\n",
        "        print(\"Detected symmetric distance matrix. Optimizing computation...\")\n",
        "        dist_condensed = pdist(matrix_one, metric=metric)   # Compute condensed distance form\n",
        "        dist_matrix = squareform(dist_condensed)            # Convert to full symmetric distance matrix\n",
        "        return dist_matrix\n",
        "    else:\n",
        "        # Compute full distance matrix between matrix_one and matrix_two\n",
        "        return cdist(matrix_one, matrix_two, metric=metric)\n",
        "\n",
        "def compute_test_weights(\n",
        "    distances: np.ndarray,\n",
        "    h: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute similarity-based weights from a distance matrix.\n",
        "\n",
        "    Parameters:\n",
        "        distances : np.ndarray\n",
        "            Distance matrix of shape (n_samples_test, n_samples_train)\n",
        "        h         : float\n",
        "            Similarity decay parameter that controls sharpness of the weighting function\n",
        "\n",
        "    Returns:\n",
        "        weights : np.ndarray\n",
        "            Similarity weights of shape (n_samples_test, n_samples_train)\n",
        "    \"\"\"\n",
        "    # Compute the standard deviation across all distances\n",
        "    s_q = np.std(distances)\n",
        "\n",
        "    # Avoid division by zero in case of constant distances\n",
        "    if s_q == 0:\n",
        "        s_q = 1e-6\n",
        "\n",
        "    # Compute similarity-based weights using exponential decay\n",
        "    weights = np.exp(-distances / (s_q * h))\n",
        "\n",
        "    return weights\n",
        "\n",
        "def perform_weighted_pls_crossvalidation(\n",
        "    x_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    distance_matrix: np.ndarray,\n",
        "    n_splits: int,\n",
        "    n_latent_variables: int,\n",
        "    h: float,\n",
        "    random_state: int\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Perform stratified K-fold cross-validation using similarity-weighted PLS \n",
        "    with centering and unnormalized weights.\n",
        "\n",
        "    Parameters:\n",
        "        x_train            : Training features of shape (n_samples, n_features)\n",
        "        y_train            : Training targets of shape (n_samples,)\n",
        "        distance_matrix    : Precomputed distance matrix of shape (n_samples, n_samples)\n",
        "        n_splits           : Number of CV folds\n",
        "        n_latent_variables : Number of latent variables (PLS components)\n",
        "        h                  : Similarity decay parameter\n",
        "        random_state       : Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        rmse_cv            : Root mean squared error over all validation folds\n",
        "    \"\"\"\n",
        "    # Flatten target array and bin it for stratification\n",
        "    y_train = y_train.flatten()\n",
        "    y_binned = pd.qcut(y_train, q=10, labels=False, duplicates='drop')\n",
        "\n",
        "    # Initialize stratified K-Fold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    all_squared_errors = []\n",
        "\n",
        "    # Loop over CV folds\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(x_train, y_binned)):\n",
        "        # Split into training and validation sets for this fold\n",
        "        X_tr, Y_tr = x_train[train_idx], y_train[train_idx]\n",
        "        X_val, Y_val = x_train[val_idx], y_train[val_idx]\n",
        "\n",
        "        # Extract distances from training to validation samples\n",
        "        train_to_val_distances = distance_matrix[np.ix_(train_idx, val_idx)]  # (n_train, n_val)\n",
        "\n",
        "        # Compute similarity weights from validation to training\n",
        "        val_weights = compute_test_weights(train_to_val_distances.T, h)       # (n_val, n_train)\n",
        "\n",
        "        # Average the similarity weights over all validation points\n",
        "        mean_weight_vector = val_weights.mean(axis=0)                         # (n_train,)\n",
        "\n",
        "        # Compute weighted means for centering\n",
        "        x_mean = np.average(X_tr, axis=0, weights=mean_weight_vector)\n",
        "        y_mean = np.average(Y_tr, weights=mean_weight_vector)\n",
        "\n",
        "        # Center training data\n",
        "        X_tr_centered = X_tr - x_mean\n",
        "        Y_tr_centered = Y_tr - y_mean\n",
        "\n",
        "        # Apply similarity weights to centered data\n",
        "        X_w = X_tr_centered * mean_weight_vector[:, None]\n",
        "        Y_w = Y_tr_centered * mean_weight_vector\n",
        "\n",
        "        # Fit PLS model on weighted, centered training data\n",
        "        pls = PLSRegression(n_components=n_latent_variables)\n",
        "        pls.fit(X_w, Y_w)\n",
        "\n",
        "        # Center validation features using training mean and predict\n",
        "        X_val_centered = X_val - x_mean\n",
        "        Y_pred_val = pls.predict(X_val_centered).flatten() + y_mean\n",
        "\n",
        "        # Compute squared errors and store them\n",
        "        squared_errors = (Y_val - Y_pred_val) ** 2\n",
        "        all_squared_errors.extend(squared_errors)\n",
        "\n",
        "    # Compute and print final CV RMSE\n",
        "    rmse_cv = np.sqrt(np.mean(all_squared_errors))\n",
        "    print(f\"Finished Stratified CV: RMSE = {rmse_cv:.4f}\")\n",
        "\n",
        "    return rmse_cv\n",
        "\n",
        "def perform_gridsearch(\n",
        "    x_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    distance_metrics: list,\n",
        "    h_values: list,\n",
        "    max_n_latent_variables: int,\n",
        "    n_splits: int,\n",
        "    random_state: int\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Perform grid search over distance metrics, h-values, and number of latent variables\n",
        "    for similarity-weighted PLS regression.\n",
        "\n",
        "    Parameters:\n",
        "        x_train                : Training feature matrix (n_samples, n_features)\n",
        "        y_train                : Training target array (n_samples,)\n",
        "        distance_metrics       : List of distance metric names (e.g., ['euclidean', 'cosine'])\n",
        "        h_values               : List of h-values controlling similarity decay\n",
        "        max_n_latent_variables : Maximum number of PLS components to evaluate\n",
        "        n_splits               : Number of folds for stratified K-Fold CV\n",
        "        random_state           : Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame : DataFrame containing all evaluated hyperparameter combinations and their RMSECV\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for metric in distance_metrics:\n",
        "        print(f\"\\nPrecomputing distance matrix for metric: {metric}\")\n",
        "        # Precompute distance matrix for the current metric\n",
        "        distance_matrix = compute_distance_matrix(x_train, x_train, metric=metric)\n",
        "\n",
        "        for h in h_values:\n",
        "            print(f\"\\nRunning grid search for h = {h:.2f} with distance metric: {metric}\")\n",
        "\n",
        "            for n_lv in range(1, max_n_latent_variables + 1):\n",
        "                print(f\"   Evaluating with {n_lv} latent variables...\")\n",
        "\n",
        "                # Perform CV for current combination of hyperparameters\n",
        "                rmse_cv = perform_weighted_pls_crossvalidation(\n",
        "                    x_train=x_train,\n",
        "                    y_train=y_train,\n",
        "                    distance_matrix=distance_matrix,\n",
        "                    n_splits=n_splits,\n",
        "                    n_latent_variables=n_lv,\n",
        "                    h=h,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "                # Store results\n",
        "                results.append({\n",
        "                    \"distance_metric\": metric,\n",
        "                    \"h\": h,\n",
        "                    \"n_components\": n_lv,\n",
        "                    \"RMSECV\": rmse_cv\n",
        "                })\n",
        "\n",
        "    # Compile all results into a DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nGrid search completed.\")\n",
        "    return results_df\n",
        "\n",
        "def evaluate_gridsearch(\n",
        "    gridsearch_df: pd.DataFrame\n",
        ") -> Tuple[pd.DataFrame, dict]:\n",
        "    \"\"\"\n",
        "    Evaluate a grid search results DataFrame by identifying the optimal number of\n",
        "    latent variables (A) per (distance_metric, h) pair using knee point detection.\n",
        "    Also determines the overall best configuration.\n",
        "\n",
        "    Parameters:\n",
        "        gridsearch_df : DataFrame with columns ['distance_metric', 'h', 'n_components', 'RMSECV']\n",
        "\n",
        "    Returns:\n",
        "        knees_df      : DataFrame listing best A and RMSECV for each (distance_metric, h)\n",
        "        best_result   : Dictionary containing the overall best configuration\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # === Loop over each distance metric ===\n",
        "    for metric in gridsearch_df[\"distance_metric\"].unique():\n",
        "        df_metric = gridsearch_df[gridsearch_df[\"distance_metric\"] == metric]\n",
        "\n",
        "        # === Loop over each h-value for this metric ===\n",
        "        for h_val in sorted(df_metric[\"h\"].unique()):\n",
        "            # Subset and sort rows by number of components\n",
        "            subset = df_metric[df_metric[\"h\"] == h_val].sort_values(\"n_components\")\n",
        "            A_vals = subset[\"n_components\"].values\n",
        "            rmse_vals = subset[\"RMSECV\"].values\n",
        "\n",
        "            # === Detect knee in the RMSECV curve ===\n",
        "            knee_locator = KneeLocator(\n",
        "                A_vals, rmse_vals,\n",
        "                curve=\"convex\", direction=\"decreasing\", S=1.5\n",
        "            )\n",
        "\n",
        "            if knee_locator.knee is not None:\n",
        "                best_idx = np.where(A_vals == knee_locator.knee)[0][0]\n",
        "            else:\n",
        "                best_idx = int(np.argmin(rmse_vals))  # Fallback to minimum RMSECV\n",
        "\n",
        "            # === Store result ===\n",
        "            results.append({\n",
        "                \"distance_metric\": metric,\n",
        "                \"h\": h_val,\n",
        "                \"n_components\": A_vals[best_idx],\n",
        "                \"RMSECV\": rmse_vals[best_idx]\n",
        "            })\n",
        "\n",
        "            # === Plot RMSECV curve and selected knee ===\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            plt.plot(A_vals, rmse_vals, marker=\"o\", label=f\"h = {h_val}\")\n",
        "            plt.axvline(x=A_vals[best_idx], color=\"red\", linestyle=\"--\", label=f\"Knee at A = {A_vals[best_idx]}\")\n",
        "            plt.title(f\"RMSECV vs. Latent Variables\\nDistance: {metric}, h = {h_val}\")\n",
        "            plt.xlabel(\"Number of Latent Variables (A)\")\n",
        "            plt.ylabel(\"RMSECV\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    # === Compile knee results into DataFrame ===\n",
        "    knees_df = pd.DataFrame(results)\n",
        "\n",
        "    if knees_df.empty:\n",
        "        raise ValueError(\"No valid knee points found in the grid search results.\")\n",
        "\n",
        "    # === Get the best overall result (lowest RMSECV) ===\n",
        "    best_row = knees_df.loc[knees_df[\"RMSECV\"].idxmin()]\n",
        "    best_result = {\n",
        "        \"distance_metric\": best_row[\"distance_metric\"],\n",
        "        \"h\": best_row[\"h\"],\n",
        "        \"n_components\": int(best_row[\"n_components\"]),\n",
        "        \"RMSECV\": float(best_row[\"RMSECV\"])\n",
        "    }\n",
        "\n",
        "    # === Print best configuration summary ===\n",
        "    print(\"\\n=== Best Configuration Found ===\")\n",
        "    for k, v in best_result.items():\n",
        "        print(f\"{k:<17}: {v}\")\n",
        "\n",
        "    return knees_df, best_result\n",
        "\n",
        "def test_lwpls(\n",
        "    x_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    x_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    h: float,\n",
        "    n_components: int,\n",
        "    distance_metric: str\n",
        ") -> Tuple[pd.DataFrame, float, float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate LWPLS on a test set using best hyperparameters.\n",
        "\n",
        "    Parameters:\n",
        "        x_train        : Training feature matrix\n",
        "        y_train        : Training target array\n",
        "        x_test         : Test feature matrix\n",
        "        y_test         : Test target array\n",
        "        h              : Similarity decay factor\n",
        "        n_components   : Number of PLS components\n",
        "        distance_metric: Distance metric to use ('euclidean', 'cosine', etc.)\n",
        "\n",
        "    Returns:\n",
        "        df_results         : DataFrame with observed and predicted values\n",
        "        rmsep              : Root mean squared error of prediction\n",
        "        r2                 : Coefficient of determination\n",
        "        practical_accuracy : % predictions within ±20% relative error\n",
        "    \"\"\"\n",
        "    # Flatten target arrays\n",
        "    y_train = y_train.flatten()\n",
        "    y_true = y_test.flatten()\n",
        "\n",
        "    # === Step 1: Compute distances and similarity weights ===\n",
        "    test_distances = compute_distance_matrix(x_test, x_train, distance_metric)  # shape: (n_test, n_train)\n",
        "    test_weights = compute_test_weights(test_distances, h)                      # shape: (n_test, n_train)\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    # === Step 2: Loop over each test sample ===\n",
        "    for i in range(x_test.shape[0]):\n",
        "        weights_i = test_weights[i]  # similarity weights for current test sample\n",
        "\n",
        "        # Compute weighted means for centering \n",
        "        x_mean = np.average(x_train, axis=0, weights=weights_i)\n",
        "        y_mean = np.average(y_train, weights=weights_i)\n",
        "\n",
        "        # Center training data\n",
        "        x_centered = x_train - x_mean\n",
        "        y_centered = y_train - y_mean\n",
        "\n",
        "        # Apply similarity weights \n",
        "        x_w = x_centered * weights_i[:, None]  # shape: (n_train, n_features)\n",
        "        y_w = y_centered * weights_i           # shape: (n_train,)\n",
        "\n",
        "        # Fit weighted PLS model \n",
        "        pls = PLSRegression(n_components=n_components)\n",
        "        pls.fit(x_w, y_w)\n",
        "\n",
        "        # Center test sample and predict \n",
        "        x_test_centered = x_test[i] - x_mean\n",
        "        y_pred_i = pls.predict(x_test_centered.reshape(1, -1)).flatten()[0] + y_mean\n",
        "        predictions.append(y_pred_i)\n",
        "\n",
        "        # Print progress every 10 samples or on final sample \n",
        "        if (i + 1) % 10 == 0 or (i + 1) == x_test.shape[0]:\n",
        "            current_rmsep = np.sqrt(mean_squared_error(y_true[:i + 1], predictions))\n",
        "            print(f\"{i + 1}/{x_test.shape[0]} samples done - current RMSEP: {current_rmsep:.4f}\")\n",
        "\n",
        "    # === Step 3: Compute final performance metrics ===\n",
        "    y_pred = np.array(predictions)\n",
        "\n",
        "    rmsep = np.sqrt(mean_squared_error(y_true, y_pred))              # Root Mean Squared Error\n",
        "    r2 = r2_score(y_true, y_pred)                                    # R² score\n",
        "    pct_error = np.abs(y_pred - y_true) / np.abs(y_true)\n",
        "    practical_accuracy = np.mean(pct_error <= 0.2) * 100             # % of predictions within ±20%\n",
        "\n",
        "    # === Step 4: Compile prediction results into a DataFrame ===\n",
        "    df_results = pd.DataFrame({\n",
        "        \"observed\": y_true,\n",
        "        \"predicted\": y_pred\n",
        "    })\n",
        "\n",
        "    # === Step 5: Print summary metrics ===\n",
        "    print(f\"Test RMSEP: {rmsep:.4f}\")\n",
        "    print(f\"Test R2: {r2:.4f}\")\n",
        "    print(f\"Practical accuracy (±20% error): {practical_accuracy:.2f}%\")\n",
        "\n",
        "    return df_results, rmsep, r2, practical_accuracy\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479366988
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Parameters_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DF                  = df\n",
        "TEST_VARIETY        = \"TestVariety\"\n",
        "TEST_SEASON         = 2025\n",
        "RANDOM_STATE        = 27\n",
        "H_VALUES            = [round(h, 2) for h in np.arange(0.1, 2.01, 0.1)]\n",
        "MAX_COMPONENTS      = 20\n",
        "N_SPLITS            = 3\n",
        "DISTANCE_METRICS    = ['euclidean', 'correlation', 'cosine']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479370326
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Run_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Split into train and test sets ===\n",
        "df_train, df_test_variety, df_test_season = split_train_test(\n",
        "    df,\n",
        "    test_variety=TEST_VARIETY,\n",
        "    test_season=TEST_SEASON\n",
        ")\n",
        "\n",
        "# === Convert to x and y arrays ===\n",
        "x_train, y_train = split_x_y(\n",
        "    df_train,\n",
        ")\n",
        "x_test_variety, y_test_variety = split_x_y(\n",
        "    df_test_variety,\n",
        ")\n",
        "x_test_season, y_test_season = split_x_y(\n",
        "    df_test_season,\n",
        ")\n",
        "\n",
        "# === Hyperparameter Search ===\n",
        "cv_results_all = perform_gridsearch(\n",
        "    x_train=x_train,\n",
        "    y_train=y_train,\n",
        "    distance_metrics=DISTANCE_METRICS,\n",
        "    h_values=H_VALUES,\n",
        "    max_n_latent_variables=MAX_COMPONENTS,\n",
        "    n_splits=N_SPLITS,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# === Evaluate Grid Search ===\n",
        "knees_df, best_result = evaluate_gridsearch(\n",
        "    cv_results_all\n",
        ")\n",
        "\n",
        "print(\"Best Configuration Summary:\")\n",
        "print(best_result)\n",
        "\n",
        "# === Final Test Set Evaluation ===\n",
        "df_results_variety, lwpls_rmsep_variety, lwpls_r2_variety, lwpls_practical_accuracy_variety = test_lwpls(\n",
        "    x_train=x_train,\n",
        "    y_train=y_train,\n",
        "    x_test=x_test_variety,\n",
        "    y_test=y_test_variety,\n",
        "    h=best_result[\"h\"],\n",
        "    n_components=best_result[\"n_components\"],\n",
        "    distance_metric=best_result[\"distance_metric\"]\n",
        ")\n",
        "\n",
        "df_results_season, lwpls_rmsep_season, lwpls_r2_season, lwpls_practical_accuracy_season = test_lwpls(\n",
        "    x_train=x_train,\n",
        "    y_train=y_train,\n",
        "    x_test=x_test_season,\n",
        "    y_test=y_test_season,\n",
        "    h=best_result[\"h\"],\n",
        "    n_components=best_result[\"n_components\"],\n",
        "    distance_metric=best_result[\"distance_metric\"]\n",
        ")\n",
        "\n",
        "results_overview = pd.DataFrame({\n",
        "    \"RMSEP\": [lwpls_rmsep_variety, lwpls_rmsep_season],\n",
        "    \"R²\": [lwpls_r2_variety, lwpls_r2_season],\n",
        "    \"Practical Accuracy (%)\": [lwpls_practical_accuracy_variety, lwpls_practical_accuracy_season]\n",
        "}, index=[\"Variety Test\", \"Season Test\"])\n",
        "\n",
        "print(results_overview)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479375072
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Inference Time Analysis_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_sample_set(\n",
        "    df_variety: pd.DataFrame,\n",
        "    df_season: pd.DataFrame,\n",
        "    random_state: int,\n",
        "    sample_size: int = 1000\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Combine two test sets (variety and season), sample rows randomly, and return X and y arrays.\n",
        "\n",
        "    Parameters:\n",
        "        df_variety   : DataFrame for variety-based test set\n",
        "        df_season    : DataFrame for season-based test set\n",
        "        random_state : Random seed for reproducibility\n",
        "        sample_size  : Number of rows to sample from combined test set\n",
        "\n",
        "    Returns:\n",
        "        x_sample : NumPy array of shape (sample_size, n_features) with spectral features\n",
        "        y_sample : NumPy array of shape (sample_size,) with corresponding Brix values\n",
        "    \"\"\"\n",
        "    # Combine the two test sets\n",
        "    df_combined = pd.concat([df_variety, df_season], axis=0)\n",
        "\n",
        "    # Randomly sample rows from the combined test set\n",
        "    df_sample = df_combined.sample(\n",
        "        n=sample_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Split into X and y arrays\n",
        "    x_sample, y_sample = split_x_y(df_sample)\n",
        "\n",
        "    return x_sample, y_sample\n",
        "\n",
        "def test_lwpls_inference_time(\n",
        "    x_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    x_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    h: float,\n",
        "    n_components: int,\n",
        "    distance_metric: str\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Compute average inference time per LWPLS prediction (in milliseconds).\n",
        "    Includes distance calculation, weight computation, model fitting, and prediction\n",
        "    for each test sample individually.\n",
        "\n",
        "    Parameters:\n",
        "        x_train        : Training features (n_train, n_features)\n",
        "        y_train        : Training targets (n_train,)\n",
        "        x_test         : Test features (n_test, n_features)\n",
        "        y_test         : Test targets (n_test,)\n",
        "        h              : Similarity decay parameter\n",
        "        n_components   : Number of PLS components\n",
        "        distance_metric: Distance metric to use ('euclidean', 'cosine', etc.)\n",
        "\n",
        "    Returns:\n",
        "        avg_inference_time_ms : Average inference time per sample (in milliseconds)\n",
        "    \"\"\"\n",
        "    y_train = y_train.flatten()\n",
        "    inference_times = []\n",
        "\n",
        "    for i in range(x_test.shape[0]):\n",
        "        start_time = time.perf_counter()\n",
        "\n",
        "        # Compute distances and similarity weights\n",
        "        dists_i = compute_distance_matrix(x_test[i].reshape(1, -1), x_train, distance_metric)[0]\n",
        "        weights_i = compute_test_weights(dists_i.reshape(1, -1), h)[0]\n",
        "\n",
        "        # Weighted means for centering\n",
        "        x_mean = np.average(x_train, axis=0, weights=weights_i)\n",
        "        y_mean = np.average(y_train, weights=weights_i)\n",
        "\n",
        "        # Center and weight training data\n",
        "        x_centered = x_train - x_mean\n",
        "        y_centered = y_train - y_mean\n",
        "        x_w = x_centered * weights_i[:, None]\n",
        "        y_w = y_centered * weights_i\n",
        "\n",
        "        # Fit model and predict\n",
        "        pls = PLSRegression(n_components=n_components)\n",
        "        pls.fit(x_w, y_w)\n",
        "\n",
        "        x_test_centered = x_test[i] - x_mean\n",
        "        _ = pls.predict(x_test_centered.reshape(1, -1)).flatten()[0] + y_mean\n",
        "\n",
        "        end_time = time.perf_counter()\n",
        "        inference_times.append(end_time - start_time)\n",
        " \n",
        "\n",
        "    avg_inference_time_ms = np.mean(inference_times) * 1000\n",
        "\n",
        "    print(f\"Average inference time: {avg_inference_time_ms:.3f} ms/sample\")\n",
        "\n",
        "    return avg_inference_time_ms\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479988947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Create sample set for inference time measurement ===\n",
        "x_inference_time, y_inference_time = get_inference_sample_set(\n",
        "    df_test_variety,\n",
        "    df_test_season,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# === Compute the average inference time ===\n",
        "inference_time_ms = test_lwpls_inference_time(\n",
        "    x_train=x_train,\n",
        "    y_train=y_train,\n",
        "    x_test=x_inference_time,\n",
        "    y_test=y_inference_time,\n",
        "    h=best_result[\"h\"],                             \n",
        "    n_components=best_result[\"n_components\"],       \n",
        "    distance_metric=best_result[\"distance_metric\"]  \n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754479991020
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}