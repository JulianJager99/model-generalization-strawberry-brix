# Code for "Evaluating Model Generalization for Brix Prediction in Strawberries Using NIR Spectroscopy"

## Abstract
This study investigates Brix prediction in strawberries using near-infrared spectroscopy, focusing on generalization across cultivars and harvest seasons. Seven predictive models are evaluated: Partial Least Squares, Iteratively Reweighted Partial Least Squares, Locally Weighted Partial Least Squares, a Convolutional Neural Network, two Bayesian Convolutional Neural Networks, and a novel Transformer-based model, SpecTransformer. SpecTransformer achieves the strongest performance in both generalization settings, evaluated using root mean squared error, explained variance, and field-required accuracy, albeit with increased sensitivity to label noise and reduced data efficiency. Both the Convolutional Neural Network and its Bayesian counterpart with a Bayesian convolutional layer perform competitively on generalization tasks. However, while the Convolutional Neural Network demonstrates strong robustness to label noise and data scarcity, the Bayesian version sacrifices much of this robustness. All deep learning models enable fast inference for in-field adoption, while consistently outperforming PLS methods in predictive performance. Finally, a predictive uncertainty framework is introduced using a Bayesian Convolutional Neural Network with Bayesian fully connected layers. Its uncertainty estimates are strongly correlated with prediction error across all models, enabling risk-aware quality monitoring in real-world applications. 

## Overview
This repository contains the full codebase for the paper "Evaluating Model Generalization for Brix Prediction in Strawberries Using NIR Spectroscopy". It includes training, evaluation, and analysis scripts for a range of predictive models using near-infrared (NIR) spectral data.

The following models are implemented: PLS, irPLS, lwPLS, CNN, BayesConv-CNN, BayesFC-CNN, and SpecTransformer. Each model is trained on spectral inputs to predict Brix values and is evaluated on RMSEP, RÂ², and Practical Accuracy. Inference time analysis is also included to assess computational efficiency.

The `99-posthoc.ipynb` notebook includes all steps performed after obtaining model predictions. This includes constructing datasets for sensitivity analysis (e.g., with added label noise), performing model comparisons using the Model Confidence Set (MCS) procedure, and bootstrap-based comparisons of performance metrics. It also includes correlation analyses between model uncertainty and predictive performance, using both 100 MC and 10 MC forward passes from BayesFC-CNN.
