{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### _Setup_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset memory\n",
        "%reset -f"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491277311
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages\n",
        "from typing import Union, List, Tuple, Dict, Any, Optional\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, initializers, optimizers, callbacks\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "import optuna"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491360290
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "df = pd.read_csv('data.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491388345
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Functions_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_col_index_of_spectra(\n",
        "    df: pd.DataFrame\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Find the column index where spectral data starts.\n",
        "\n",
        "    Assumes spectral column names can be converted to float (e.g., \"730.5\", \"731.0\").\n",
        "\n",
        "    Parameters:\n",
        "        df : Input DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Index of the first spectral column, or -1 if not found.\n",
        "    \"\"\"\n",
        "    for idx, col in enumerate(df.columns):\n",
        "        try:\n",
        "            float(col)\n",
        "            return idx\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "    return -1\n",
        "\n",
        "def split_train_test(\n",
        "    df: pd.DataFrame,\n",
        "    test_variety: str,\n",
        "    test_season: int       \n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into one training set and two test sets:\n",
        "\n",
        "    - Variety test set: Variety == test_variety AND Year == 2024\n",
        "    - Season test set : Year == test_season \n",
        "\n",
        "    The training set excludes all rows that belong to any of the test sets.\n",
        "    The season test set only includes varieties that are present in the training set.\n",
        "\n",
        "    Parameters:\n",
        "        df           : Full pandas DataFrame\n",
        "        test_variety : Variety used for the test set\n",
        "        test_season  : Year used for the season test\n",
        "\n",
        "    Returns:\n",
        "        df_train        : Training set\n",
        "        df_test_variety : Test set for specified variety and 2024\n",
        "        df_test_season  : Test set for specified season (filtered by train varieties)\n",
        "    \"\"\"\n",
        "\n",
        "    # Select test set for the specified variety in year 2024\n",
        "    df_test_variety = df[\n",
        "        (df[\"Variety\"] == test_variety) &\n",
        "        (df[\"Scan Date Year\"] == 2024)\n",
        "    ]\n",
        "\n",
        "    # Select test set for the specified season (regardless of variety)\n",
        "    df_test_season = df[\n",
        "        df[\"Scan Date Year\"] == test_season\n",
        "    ]\n",
        "\n",
        "    # Select training set (exclude test variety and test season)\n",
        "    df_train = df[\n",
        "        (df[\"Variety\"] != test_variety) &\n",
        "        (df[\"Scan Date Year\"] != test_season)\n",
        "    ]\n",
        "\n",
        "    # Filter season test set to only include varieties present in training set\n",
        "    train_varieties = df_train[\"Variety\"].unique()\n",
        "    df_test_season = df_test_season[\n",
        "        df_test_season[\"Variety\"].isin(train_varieties)\n",
        "    ]\n",
        "\n",
        "    return df_train, df_test_variety, df_test_season\n",
        "\n",
        "def take_subset(\n",
        "    df: pd.DataFrame, \n",
        "    n_subset: int,\n",
        "    random_state: int\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Return a stratified subset of the DataFrame based on 10 Brix bins.\n",
        "\n",
        "    If n_subset >= len(df), the original DataFrame is returned.\n",
        "\n",
        "    Parameters:\n",
        "        df       : Input DataFrame with 'Brix (Position)' column\n",
        "        n_subset : Desired subset size\n",
        "        random_state : Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        Subset of df with stratification over 10 quantile bins of Brix\n",
        "    \"\"\"\n",
        "    # If requested subset size exceeds full dataset, return a copy of the full DataFrame\n",
        "    if n_subset >= len(df):\n",
        "        return df.copy()\n",
        "\n",
        "    # Bin the Brix values into 10 quantile-based bins for stratification\n",
        "    binned = pd.qcut(df[\"Brix (Position)\"], q=10, labels=False, duplicates='drop')\n",
        "\n",
        "    # Initialize stratified sampler\n",
        "    splitter = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=n_subset,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Perform stratified split and extract subset indices\n",
        "    idx_subset, _ = next(splitter.split(df, binned))\n",
        "\n",
        "    # Return the stratified subset as a new DataFrame with reset index\n",
        "    return df.iloc[idx_subset].reset_index(drop=True)\n",
        "\n",
        "def create_train_val_split(\n",
        "    df: pd.DataFrame,\n",
        "    validation_size: float,\n",
        "    random_state: int\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into train and validation sets using stratified sampling\n",
        "    based on 10 quantile bins of the 'Brix (Position)' column.\n",
        "\n",
        "    Parameters:\n",
        "        df              : Input DataFrame\n",
        "        validation_size : Proportion of validation samples (0 < float < 1)\n",
        "        random_state    : Seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        df_train, df_val : Stratified training and validation DataFrames\n",
        "    \"\"\"\n",
        "    # Bin the Brix values into 10 quantile-based bins for stratified splitting\n",
        "    binned = pd.qcut(df[\"Brix (Position)\"], q=10, labels=False, duplicates=\"drop\")\n",
        "\n",
        "    # Perform stratified train/validation split based on the binned Brix values\n",
        "    df_train, df_val = train_test_split(\n",
        "        df,\n",
        "        test_size=validation_size,\n",
        "        random_state=random_state,\n",
        "        stratify=binned\n",
        "    )\n",
        "\n",
        "    # Return splits with reset indices\n",
        "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True)\n",
        "\n",
        "def split_x_y(\n",
        "    df: pd.DataFrame,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into X (spectral features) and y (target) arrays.\n",
        "    Assumes find_col_index_of_spectra() is defined globally and returns the index\n",
        "    where spectral data starts.\n",
        "\n",
        "    Parameters:\n",
        "        df : Input DataFrame containing both metadata and spectral data.\n",
        "\n",
        "    Returns:\n",
        "        x : NumPy array of shape (n_samples, n_spectral_features)\n",
        "        y : NumPy array of shape (n_samples, 1) containing Brix values\n",
        "    \"\"\"\n",
        "    # Identify spectral columns (those that can be cast to float, e.g. wavelengths)\n",
        "    spectra_cols = list(df.columns[find_col_index_of_spectra(df):])\n",
        "\n",
        "    # Define the target column\n",
        "    target_cols = ['Brix (Position)']\n",
        "\n",
        "    # Extract feature and target arrays\n",
        "    x = df[spectra_cols].values\n",
        "    y = df[target_cols].values\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def make_loader(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    batch_size: int,\n",
        "    shuffle: bool = False\n",
        ") -> DataLoader:\n",
        "    \"\"\"\n",
        "    Converts numpy arrays into a PyTorch DataLoader for use with ViT-style models.\n",
        "\n",
        "    Parameters:\n",
        "        x         : np.ndarray\n",
        "            Feature array of shape (N, L), where N is the number of samples and L is the sequence length.\n",
        "        y         : np.ndarray\n",
        "            Target array of shape (N,) or (N, 1).\n",
        "        batch_size: int\n",
        "            Batch size for DataLoader.\n",
        "        shuffle   : bool\n",
        "            Whether to shuffle the dataset during iteration (default: False).\n",
        "\n",
        "    Returns:\n",
        "        DataLoader : PyTorch DataLoader yielding batches of (x, y) formatted for ViT.\n",
        "    \"\"\"\n",
        "    # Convert input arrays to float tensors\n",
        "    x_tensor = torch.from_numpy(x).float().unsqueeze(1).unsqueeze(-1)  # Shape: (N, 1, L, 1)\n",
        "    y_tensor = torch.from_numpy(y).float().view(-1, 1)                 # Shape: (N, 1)\n",
        "\n",
        "    # Create a dataset and wrap in a DataLoader\n",
        "    dataset = TensorDataset(x_tensor, y_tensor)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return loader\n",
        "\n",
        "def model_spectransformer(\n",
        "    spectrum_length: int,\n",
        "    patch_size: int,\n",
        "    dim: int,\n",
        "    depth: int,\n",
        "    heads: int,\n",
        "    mlp_dim: int,\n",
        "    pool: str,\n",
        "    dropout: float,\n",
        "    emb_dropout: float,\n",
        "    device: str = None\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Build a Vision Transformer (ViT) model for regression on spectral data.\n",
        "\n",
        "    Parameters:\n",
        "        spectrum_length : int\n",
        "            Number of input features in the spectrum (1D input length).\n",
        "        patch_size      : int\n",
        "            Patch size to divide the spectrum into. Must divide spectrum_length evenly.\n",
        "        dim             : int\n",
        "            Dimensionality of the token embeddings.\n",
        "        depth           : int\n",
        "            Number of Transformer encoder blocks.\n",
        "        heads           : int\n",
        "            Number of attention heads in each multi-head attention layer.\n",
        "        mlp_dim         : int\n",
        "            Hidden dimension of the MLP in each Transformer block.\n",
        "        pool            : str\n",
        "            Pooling strategy before final head ('cls' or 'mean').\n",
        "        dropout         : float\n",
        "            Dropout rate within attention and MLP blocks.\n",
        "        emb_dropout     : float\n",
        "            Dropout rate applied after patch embedding and positional encoding.\n",
        "        device          : str, optional\n",
        "            Device to place the model on. Defaults to 'cuda' if available.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module\n",
        "            A configured Vision Transformer model (ViT) for 1D spectral regression.\n",
        "    \"\"\"\n",
        "\n",
        "    # Default to GPU if available\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Instantiate the ViT model configured for 1D spectral input\n",
        "    model = ViT(\n",
        "        image_size=(spectrum_length, 1),     # Treat spectrum as 1D image\n",
        "        patch_size=(patch_size, 1),          # Divide spectrum into vertical patches\n",
        "        num_classes=1,                       # Regression output (1 value)\n",
        "        dim=dim,                             # Embedding dimension\n",
        "        depth=depth,                         # Number of transformer layers\n",
        "        heads=heads,                         # Attention heads\n",
        "        mlp_dim=mlp_dim,                     # Feedforward MLP dimension\n",
        "        pool=pool,                           # Pooling strategy: 'cls' or 'mean'\n",
        "        dropout=dropout,                     # Dropout in attention/MLP blocks\n",
        "        emb_dropout=emb_dropout              # Dropout after embedding + position\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_spectransformer(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs: int,\n",
        "    learning_rate: float,\n",
        "    lr_scheduler_patience: int,\n",
        "    weight_decay: float,\n",
        "    early_stopping_patience: int\n",
        ") -> Tuple[float, nn.Module]:\n",
        "    \"\"\"\n",
        "    Train a Spectral Vision Transformer (SpecTransformer) model using RMSE loss and early stopping.\n",
        "\n",
        "    Parameters:\n",
        "        model                  : ViT model to be trained.\n",
        "        train_loader           : PyTorch DataLoader with training data.\n",
        "        val_loader             : PyTorch DataLoader with validation data (can be None).\n",
        "        epochs                 : Maximum number of training epochs.\n",
        "        learning_rate          : Initial learning rate for the optimizer.\n",
        "        lr_scheduler_patience  : Patience for learning rate scheduler.\n",
        "        weight_decay           : Weight decay (L2 regularization) for optimizer.\n",
        "        early_stopping_patience: Epochs to wait before early stopping without improvement.\n",
        "\n",
        "    Returns:\n",
        "        best_rmse : Best observed RMSE on the monitored set (validation or training).\n",
        "        model     : Trained PyTorch model with best observed weights.\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Loss and optimizer setup\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Learning rate scheduler: Reduce LR on plateau\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=lr_scheduler_patience,\n",
        "        min_lr=1e-6,\n",
        "        # verbose=True\n",
        "    )\n",
        "\n",
        "    best_rmse = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # === Train Phase ===\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "        train_rmse = avg_train_loss ** 0.5\n",
        "\n",
        "        # === Validation Phase ===\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            total_val_loss = 0.0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for x_batch, y_batch in val_loader:\n",
        "                    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "                    preds = model(x_batch)\n",
        "                    loss = criterion(preds, y_batch)\n",
        "                    total_val_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "            avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
        "            val_rmse = avg_val_loss ** 0.5\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
        "\n",
        "            scheduler.step(avg_val_loss)\n",
        "            current_rmse = val_rmse\n",
        "\n",
        "        else:\n",
        "            # No validation set → only monitor training RMSE\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Train RMSE: {train_rmse:.4f} (no val)\")\n",
        "            scheduler.step(avg_train_loss)\n",
        "            current_rmse = train_rmse\n",
        "\n",
        "        # === Early Stopping Check ===\n",
        "        if current_rmse < best_rmse - 1e-5:\n",
        "            best_rmse = current_rmse\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return best_rmse, model\n",
        "\n",
        "def perform_optuna_hyperparameter_optimization(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    spectrum_length: int,\n",
        "    patch_size_options: list,\n",
        "    dim_options: list,\n",
        "    depth_options: list,\n",
        "    heads_options: list,\n",
        "    mlp_dim_options: list,\n",
        "    learning_rate_range: Tuple[float, float],\n",
        "    dropout_range: Tuple[float, float],\n",
        "    emb_dropout_range: Tuple[float, float],\n",
        "    weight_decay_range: Tuple[float, float],\n",
        "    epochs: int,\n",
        "    lr_scheduler_patience: int,\n",
        "    timeout_time: int,\n",
        "    pooling_type: str = \"mean\",\n",
        "    device: torch.device = None\n",
        ") -> Tuple[optuna.Study, float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Runs Optuna hyperparameter optimization for SpectraTr model.\n",
        "\n",
        "    Arguments:\n",
        "        train_loader, val_loader: prepared DataLoader objects\n",
        "        spectrum_length: int, length of the spectrum (x_train_data.shape[1])\n",
        "        patch_size_options: list of ints, possible patch sizes to try\n",
        "        dim_options, depth_options, heads_options, mlp_dim_options: lists of options\n",
        "        learning_rate_range, weight_decay_range, dropout_range, emb_dropout_range: search spaces\n",
        "        epochs, lr_scheduler_patience: training settings\n",
        "        timeout_time: max time for Optuna study (seconds)\n",
        "        pooling_type: 'mean' or 'cls'\n",
        "        device: torch.device (optional)\n",
        "\n",
        "    Returns:\n",
        "        study, best_val_rmse, best_params\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def objective(trial):\n",
        "        patch_size = trial.suggest_categorical(\"patch_size\", patch_size_options)\n",
        "        dim = trial.suggest_categorical(\"dim\", dim_options)\n",
        "        depth = trial.suggest_categorical(\"depth\", depth_options)\n",
        "        heads = trial.suggest_categorical(\"heads\", heads_options)\n",
        "        mlp_dim = trial.suggest_categorical(\"mlp_dim\", mlp_dim_options)\n",
        "        lr = trial.suggest_float(\"learning_rate\", learning_rate_range[0], learning_rate_range[1], log=True)\n",
        "        dropout = trial.suggest_float(\"dropout\", dropout_range[0], dropout_range[1])\n",
        "        emb_dropout = trial.suggest_float(\"emb_dropout\", emb_dropout_range[0], emb_dropout_range[1])\n",
        "        weight_decay = trial.suggest_float(\"weight_decay\", weight_decay_range[0], weight_decay_range[1], log=True)\n",
        "        mlp_dim = dim // 2\n",
        "\n",
        "        print(f\"\"\"\n",
        "        --- Trial {trial.number} ---\n",
        "        patch_size   = {patch_size}\n",
        "        dim          = {dim}\n",
        "        depth        = {depth}\n",
        "        heads        = {heads}\n",
        "        mlp_dim      = {mlp_dim}\n",
        "        learning_rate= {lr:.2e}\n",
        "        dropout      = {dropout:.2f}\n",
        "        emb_dropout  = {emb_dropout:.2f}\n",
        "        weight_decay = {weight_decay:.2e}\n",
        "        ---------------------------\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "        # Model construction\n",
        "        model = model_spectransformer(\n",
        "            spectrum_length=spectrum_length,\n",
        "            patch_size=patch_size,\n",
        "            dim=dim,\n",
        "            depth=depth,\n",
        "            heads=heads,\n",
        "            mlp_dim=mlp_dim,\n",
        "            pool=pooling_type,\n",
        "            dropout=dropout,\n",
        "            emb_dropout=emb_dropout,\n",
        "        )\n",
        "\n",
        "        # Training, returns best validation RMSE\n",
        "        best_val_rmse, _ = train_spectransformer(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            epochs=epochs,\n",
        "            learning_rate=lr,\n",
        "            lr_scheduler_patience=lr_scheduler_patience,\n",
        "            early_stopping_patience=50,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "        return best_val_rmse\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, timeout=timeout_time, catch=(Exception,))\n",
        "\n",
        "    return study, float(study.best_value), study.best_params\n",
        "\n",
        "def test_spectransformer(\n",
        "    trained_model: nn.Module,\n",
        "    test_loader: torch.utils.data.DataLoader\n",
        ") -> Tuple[pd.DataFrame, float, float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate a trained SpectraTransformer on the test set.\n",
        "\n",
        "    Parameters:\n",
        "        trained_model : A fully trained SpectraTransformer model.\n",
        "        test_loader   : DataLoader containing test data.\n",
        "\n",
        "    Returns:\n",
        "        df_results            : DataFrame with true and predicted Brix values.\n",
        "        rmse                  : Root Mean Squared Error.\n",
        "        r2                    : R² score.\n",
        "        practical_accuracy    : % of predictions within ±20% of target.\n",
        "    \"\"\"\n",
        "    trained_model.eval()\n",
        "    device = next(trained_model.parameters()).device\n",
        "\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in test_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            preds = trained_model(x_batch)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_targets.append(y_batch.cpu())\n",
        "\n",
        "    y_pred = torch.cat(all_preds).numpy().flatten()\n",
        "    y_true = torch.cat(all_targets).numpy().flatten()\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    practical_accuracy = np.mean(np.abs(y_pred - y_true) <= 0.2 * y_true) * 100\n",
        "\n",
        "    print(f\"Test RMSE: {rmse:.4f}\")\n",
        "    print(f\"Test R²:   {r2:.4f}\")\n",
        "    print(f\"% within 20% of true Brix: {practical_accuracy:.2f}%\")\n",
        "\n",
        "    df_results = pd.DataFrame({\n",
        "        \"True\": y_true,\n",
        "        \"Predicted\": y_pred\n",
        "    })\n",
        "\n",
        "    return df_results, rmse, r2, practical_accuracy"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491675380
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pair(t):\n",
        "    \"\"\"\n",
        "    Ensures the input is returned as a tuple of two elements.\n",
        "\n",
        "    If the input is already a tuple, it is returned as-is.\n",
        "    Otherwise, the input is duplicated into a tuple (t, t).\n",
        "\n",
        "    Parameters:\n",
        "        t : Any\n",
        "            Input value or tuple.\n",
        "\n",
        "    Returns:\n",
        "        tuple : A 2-element tuple (t, t) or the original tuple if already a tuple.\n",
        "    \"\"\"\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "def get_sinusoidal_encoding(\n",
        "    seq_len,\n",
        "    dim\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a sinusoidal positional encoding matrix.\n",
        "\n",
        "    This function returns a tensor of shape (1, seq_len, dim), where each position\n",
        "    in the sequence has a unique encoding based on sine and cosine functions.\n",
        "    These encodings help inject position information into models such as Transformers.\n",
        "\n",
        "    Parameters:\n",
        "        seq_len : int\n",
        "            Length of the sequence (number of time steps).\n",
        "        dim     : int\n",
        "            Dimensionality of the embedding space.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Positional encoding of shape (1, seq_len, dim)\n",
        "    \"\"\"\n",
        "    # Position indices (shape: [seq_len, 1])\n",
        "    position = torch.arange(seq_len).unsqueeze(1)\n",
        "\n",
        "    # Compute the scaling factors for the sinusoidal frequencies (shape: [dim/2])\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, dim, 2) * -(np.log(10000.0) / dim)\n",
        "    )\n",
        "\n",
        "    # Initialize the positional encoding matrix (shape: [seq_len, dim])\n",
        "    pe = torch.zeros(seq_len, dim)\n",
        "\n",
        "    # Apply sine to even indices (0, 2, 4, ...) and cosine to odd indices (1, 3, 5, ...)\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # Add batch dimension -> shape: (1, seq_len, dim)\n",
        "    return pe.unsqueeze(0)\n",
        "\n",
        "def _build_mlp_head(\n",
        "    self,\n",
        "    dim,\n",
        "    mlp_dim,\n",
        "    dropout,\n",
        "    n_layers\n",
        "):\n",
        "    \"\"\"\n",
        "    Build the final MLP head for regression.\n",
        "\n",
        "    Depending on the number of layers specified, this function constructs:\n",
        "    - A simple linear layer (if n_layers == 0)\n",
        "    - A 2-layer MLP with GELU activation and dropout (if n_layers == 1)\n",
        "\n",
        "    Parameters:\n",
        "        dim      : int\n",
        "            Input dimensionality of the MLP head (typically the Transformer output dimension).\n",
        "        mlp_dim  : int\n",
        "            Hidden layer size used when n_layers == 1.\n",
        "        dropout  : float\n",
        "            Dropout rate applied after activation.\n",
        "        n_layers : int\n",
        "            Number of layers in the MLP head. Must be 0 or 1.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential : A PyTorch Sequential module representing the MLP head.\n",
        "    \"\"\"\n",
        "    layers = [nn.LayerNorm(dim)]  # Normalize input features\n",
        "\n",
        "    if n_layers == 0:\n",
        "        # Simple linear regression head\n",
        "        layers += [nn.Linear(dim, 1)]\n",
        "    elif n_layers == 1:\n",
        "        # 2-layer MLP head with GELU activation and dropout\n",
        "        layers += [\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(mlp_dim, 1)\n",
        "        ]\n",
        "    else:\n",
        "        raise ValueError(\"mlp_head_layers must be 0 or 1\")\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Applies Layer Normalization before a given function.\n",
        "\n",
        "    This wrapper is commonly used in Transformer architectures where\n",
        "    the input is normalized before being passed to a sub-layer like \n",
        "    attention or feedforward blocks.\n",
        "\n",
        "    Parameters:\n",
        "        dim : int\n",
        "            Input feature dimension for LayerNorm.\n",
        "        fn : nn.Module\n",
        "            A module (e.g., attention or MLP) that takes the normalized input.\n",
        "\n",
        "    Forward Arguments:\n",
        "        x : torch.Tensor\n",
        "            Input tensor of shape [batch_size, sequence_length, dim]\n",
        "        **kwargs : dict\n",
        "            Additional arguments passed to the wrapped function.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Output of the wrapped function after pre-normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)  # Apply normalization over last dimension\n",
        "        self.fn = fn                   # Wrapped function (e.g., Attention or FeedForward)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        # Normalize input before passing to the wrapped function\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise FeedForward layer used in Transformer blocks.\n",
        "\n",
        "    Applies two linear transformations with a GELU activation in between,\n",
        "    along with dropout for regularization. The input and output dimensions\n",
        "    are the same to allow residual connections.\n",
        "\n",
        "    Parameters:\n",
        "        dim        : int\n",
        "            Input and output feature dimension.\n",
        "        hidden_dim : int\n",
        "            Hidden layer dimension (expansion size).\n",
        "        dropout    : float\n",
        "            Dropout probability applied after each linear layer.\n",
        "\n",
        "    Forward Arguments:\n",
        "        x : torch.Tensor\n",
        "            Input tensor of shape [batch_size, sequence_length, dim].\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Output tensor of shape [batch_size, sequence_length, dim].\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),  # Project to higher dimension\n",
        "            nn.GELU(),                   # Non-linear activation\n",
        "            nn.Dropout(dropout),         # Dropout for regularization\n",
        "            nn.Linear(hidden_dim, dim),  # Project back to original dimension\n",
        "            nn.Dropout(dropout)          # Dropout again\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)  # Pass input through the feedforward block\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Self-Attention layer used in Transformer encoders.\n",
        "\n",
        "    Computes attention over sequences using multiple heads in parallel.\n",
        "    Each head operates on a different learned projection of the input.\n",
        "\n",
        "    Parameters:\n",
        "        dim       : int\n",
        "            Input and output embedding dimension.\n",
        "        heads     : int\n",
        "            Number of attention heads.\n",
        "        dim_head  : int\n",
        "            Dimensionality of each head's projection.\n",
        "        dropout   : float\n",
        "            Dropout probability applied to output projection.\n",
        "\n",
        "    Forward Arguments:\n",
        "        x : torch.Tensor\n",
        "            Input tensor of shape [batch_size, sequence_length, dim].\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Output tensor of shape [batch_size, sequence_length, dim].\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        inner_dim = dim_head * heads               # Total dimension across all heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5              # Scaling factor for attention logits\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)           # Softmax over attention weights\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)  # Combined Q, K, V projection\n",
        "\n",
        "        # Output projection: identity if only 1 head and dim_head == dim\n",
        "        self.to_out = (\n",
        "            nn.Sequential(\n",
        "                nn.Linear(inner_dim, dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) if project_out else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads  # batch_size, seq_len, _, num_heads\n",
        "\n",
        "        # Project input to Q, K, V and split them\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)  # 3 tensors: [b, n, heads * dim_head]\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), \n",
        "            qkv\n",
        "        )  # Reshape: [batch, heads, seq_len, dim_head]\n",
        "\n",
        "        # Compute scaled dot-product attention\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale  # [b, h, seq_len, seq_len]\n",
        "        attn = self.attend(dots)  # Apply softmax\n",
        "\n",
        "        # Weighted sum of values\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)  # [b, h, seq_len, dim_head]\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')  # Concatenate heads\n",
        "\n",
        "        return self.to_out(out)  # Final projection\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer encoder block composed of multiple layers.\n",
        "\n",
        "    Each layer contains:\n",
        "        - Multi-head self-attention with residual connection and layer normalization.\n",
        "        - Feedforward neural network with residual connection and layer normalization.\n",
        "\n",
        "    Parameters:\n",
        "        dim       : int\n",
        "            Input and output feature dimension.\n",
        "        depth     : int\n",
        "            Number of Transformer layers (i.e., encoder blocks).\n",
        "        heads     : int\n",
        "            Number of attention heads.\n",
        "        dim_head  : int\n",
        "            Dimensionality of each attention head.\n",
        "        mlp_dim   : int\n",
        "            Hidden layer size in the feedforward network.\n",
        "        dropout   : float\n",
        "            Dropout probability applied in attention and feedforward layers.\n",
        "\n",
        "    Forward Arguments:\n",
        "        x : torch.Tensor\n",
        "            Input tensor of shape [batch_size, seq_len, dim].\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Output tensor of shape [batch_size, seq_len, dim].\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        # Build a list of transformer layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
        "            ])\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through each attention + feedforward block\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x  # Residual connection after attention\n",
        "            x = ff(x) + x    # Residual connection after feedforward\n",
        "        return x\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    \"\"\"\n",
        "    Vision Transformer (ViT) model for image-based regression tasks.\n",
        "    \n",
        "    This implementation follows the original ViT architecture from \"An Image is Worth 16x16 Words\"\n",
        "    but is adapted for regression outputs instead of classification.\n",
        "\n",
        "    Parameters:\n",
        "        image_size   : int or tuple\n",
        "            Height and width of the input image. If int, assumes square image.\n",
        "        patch_size   : int or tuple  \n",
        "            Height and width of each image patch. If int, assumes square patches.\n",
        "        num_classes  : int\n",
        "            Legacy parameter for compatibility (not used in regression setup).\n",
        "        dim          : int\n",
        "            Dimension of the token embeddings and transformer hidden states.\n",
        "        depth        : int\n",
        "            Number of transformer encoder layers.\n",
        "        heads        : int\n",
        "            Number of attention heads in multi-head attention.\n",
        "        mlp_dim      : int\n",
        "            Hidden dimension in the transformer feedforward layers.\n",
        "        pool         : str\n",
        "            Pooling strategy: 'cls' (use CLS token) or 'mean' (average all tokens).\n",
        "        channels     : int, default=1\n",
        "            Number of input channels (1 for grayscale, 3 for RGB).\n",
        "        dropout      : float\n",
        "            Dropout rate in transformer layers.\n",
        "        emb_dropout  : float\n",
        "            Dropout rate applied after patch embedding + positional encoding.\n",
        "        dim_head     : int or None, default=None\n",
        "            Dimension of each attention head. If None, defaults to dim // heads.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        image_size,\n",
        "        patch_size,\n",
        "        num_classes,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        mlp_dim,\n",
        "        pool,\n",
        "        channels=1,\n",
        "        dropout,\n",
        "        emb_dropout,\n",
        "        dim_head=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        # === Image and patch dimension calculations ===\n",
        "        image_height, image_width = pair(image_size)  # Convert to (height, width) tuple\n",
        "        patch_height, patch_width = pair(patch_size)  # Convert to (height, width) tuple\n",
        "\n",
        "        # Ensure image dimensions are evenly divisible by patch dimensions\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, \\\n",
        "            'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        # Calculate total number of patches and flattened patch dimension\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width  # Flattened patch size\n",
        "        \n",
        "        # Validate pooling strategy\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        # === Patch embedding layer ===\n",
        "        # Converts image patches to token embeddings\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            # Rearrange image into flattened patches: (B, C, H, W) -> (B, num_patches, patch_dim)\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
        "            # Project patches to embedding dimension\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        # === Positional encoding and CLS token ===\n",
        "        # Register sinusoidal positional encodings as buffer (not trained)\n",
        "        # +1 for CLS token position\n",
        "        self.register_buffer(\"pos_embedding\", get_sinusoidal_encoding(num_patches + 1, dim))\n",
        "        \n",
        "        # Learnable CLS token (classification token) - used for final prediction\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        \n",
        "        # Dropout applied after adding positional encodings\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        # === Attention head dimension configuration ===\n",
        "        # If dim_head not specified, divide embedding dimension equally among heads\n",
        "        if dim_head is None:\n",
        "            assert dim % heads == 0, f\"dim ({dim}) must be divisible by heads ({heads})\"\n",
        "            dim_head = dim // heads\n",
        "\n",
        "        # === Transformer encoder ===\n",
        "        # Stack of transformer encoder layers with self-attention and feedforward\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        # === Pooling and output configuration ===\n",
        "        self.pool = pool  # Store pooling strategy\n",
        "        self.to_latent = nn.Identity()  # Identity layer (placeholder for potential future use)\n",
        "\n",
        "        # === Regression head ===\n",
        "        # Simple MLP head for regression output\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),      # Normalize features before final projection\n",
        "            nn.Linear(dim, 1)       # Project to single regression output\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \"\"\"\n",
        "        Forward pass through the Vision Transformer.\n",
        "\n",
        "        Parameters:\n",
        "            img : torch.Tensor\n",
        "                Input tensor of shape (B, C, H, W) where:\n",
        "                - B: batch size\n",
        "                - C: number of channels  \n",
        "                - H: image height\n",
        "                - W: image width\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor : Regression output of shape (B, 1)\n",
        "        \"\"\"\n",
        "        # === Patch embedding ===\n",
        "        # Convert image to sequence of patch embeddings\n",
        "        x = self.to_patch_embedding(img)  # Shape: (B, num_patches, dim)\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        # === Add CLS token ===\n",
        "        # Prepend learnable CLS token to sequence\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)  # Expand for batch\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # Shape: (B, num_patches+1, dim)\n",
        "        \n",
        "        # === Add positional encoding ===\n",
        "        # Add sinusoidal position encodings (slice to match sequence length)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)  # Apply dropout after position encoding\n",
        "\n",
        "        # === Transformer processing ===\n",
        "        # Pass through stack of transformer encoder layers\n",
        "        x = self.transformer(x)  # Shape: (B, num_patches+1, dim)\n",
        "\n",
        "        # === Pooling ===\n",
        "        # Extract final representation for prediction\n",
        "        if self.pool == 'mean':\n",
        "            x = x.mean(dim=1)  # Average all tokens (including CLS)\n",
        "        else:  # self.pool == 'cls'\n",
        "            x = x[:, 0]        # Use CLS token only\n",
        "        # Shape after pooling: (B, dim)\n",
        "\n",
        "        # === Final projection ===\n",
        "        x = self.to_latent(x)    # Identity transformation (no-op currently)\n",
        "        return self.mlp_head(x)  # Project to regression output (B, 1)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491442504
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Parameters_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DF              = df\n",
        "TEST_VARIETY    = \"TestVariety\"\n",
        "TEST_SEASON     = 2025\n",
        "\n",
        "RANDOM_STATE    = 27\n",
        "N_SUBSET        = 23690\n",
        "VALIDATION_SIZE = 0.1\n",
        "\n",
        "BATCH_SIZE      = 64\n",
        "SPECTRUM_LENGTH = 1026\n",
        "\n",
        "PATCH_SIZE_OPTIONS = [n for n in range(10, SPECTRUM_LENGTH) if SPECTRUM_LENGTH % n == 0]\n",
        "DIM_OPTIONS = [128, 256, 512, 1024]\n",
        "DEPTH_RANGE = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
        "HEADS_OPTIONS = [4, 8, 16]\n",
        "MLP_DIM_OPTIONS = [256, 512, 1024]\n",
        "DROPOUT_RANGE = (0.01, 0.4)\n",
        "EMB_DROPOUT_RANGE = (0.01, 0.4)\n",
        "WEIGHT_DECAY_RANGE = (0, 1e-2)\n",
        "\n",
        "EARLY_STOPPING_PATIENCE = 50\n",
        "LR_SCHEDULER_PATIENCE = 25\n",
        "\n",
        "TRAIN_EPOCHS      = 250\n",
        "TEST_EPOCHS       = 1000\n",
        "TIMEOUT_TIME      = 60 * 60 * 72\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491763626
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Run_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Split into train and test sets ===\n",
        "df_train_all, df_test_variety, df_test_season = split_train_test(\n",
        "    df,\n",
        "    test_variety=TEST_VARIETY,\n",
        "    test_season=TEST_SEASON,\n",
        ")\n",
        "\n",
        "# === Take subset ===\n",
        "df_subset = take_subset(\n",
        "    df_train_all, \n",
        "    n_subset=N_SUBSET, \n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# === Make train/validation split ===\n",
        "df_train, df_val = create_train_val_split(\n",
        "    df=df_subset,\n",
        "    validation_size=VALIDATION_SIZE,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# === Convert to x and y arrays ===\n",
        "x_train_all, y_train_all = split_x_y(\n",
        "    df_train_all,\n",
        ")\n",
        "x_train, y_train = split_x_y(\n",
        "    df_train,\n",
        ")\n",
        "x_val, y_val = split_x_y(\n",
        "    df_val,\n",
        ")\n",
        "x_test_variety, y_train_variety = split_x_y(\n",
        "    df_test_variety,\n",
        ")\n",
        "x_test_season, y_train_season = split_x_y(\n",
        "    df_test_season,\n",
        ")\n",
        "\n",
        "# === Define DataLoaders ===\n",
        "train_all_loader = make_loader(\n",
        "    x_train_all,\n",
        "    y_train_all,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "train_loader = make_loader(\n",
        "    x_train, \n",
        "    y_train, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = make_loader(\n",
        "    x_val,   \n",
        "    y_val,   \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True\n",
        ")\n",
        "test_loader_variety = make_loader(\n",
        "    x_test_variety,       \n",
        "    y_train_variety,       \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False\n",
        ")\n",
        "test_loader_season = make_loader(\n",
        "    x_test_season,       \n",
        "    y_train_season,       \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# === Run Optuna Hyperparameter Optimization ===\n",
        "study, best_val_rmse, best_params = perform_optuna_hyperparameter_optimization(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    spectrum_length=SPECTRUM_LENGTH,\n",
        "    patch_size_options=PATCH_SIZE_OPTIONS,\n",
        "    dim_options=DIM_OPTIONS,\n",
        "    depth_options=DEPTH_RANGE,\n",
        "    heads_options=HEADS_OPTIONS,\n",
        "    mlp_dim_options=MLP_DIM_OPTIONS,\n",
        "    learning_rate_range=(0.0001, 0.0001),\n",
        "    dropout_range=DROPOUT_RANGE,\n",
        "    emb_dropout_range=EMB_DROPOUT_RANGE,\n",
        "    weight_decay_range=WEIGHT_DECAY_RANGE,\n",
        "    epochs=TRAIN_EPOCHS,\n",
        "    lr_scheduler_patience=LR_SCHEDULER_PATIENCE,\n",
        "    timeout_time=TIMEOUT_TIME,\n",
        "    pooling_type='mean'\n",
        ")\n",
        "\n",
        "# === Define the model with best parameters ===\n",
        "model = model_spectransformer(\n",
        "    spectrum_length = SPECTRUM_LENGTH,\n",
        "    patch_size      = best_params[\"patch_size\"],\n",
        "    dim             = best_params[\"dim\"],\n",
        "    depth           = best_params[\"depth\"],\n",
        "    heads           = best_params[\"heads\"],\n",
        "    mlp_dim         = best_params[\"mlp_dim\"],\n",
        "    pool            = \"mean\",\n",
        "    dropout         = best_params[\"dropout\"],\n",
        "    emb_dropout     = best_params[\"emb_dropout\"],\n",
        ")\n",
        "\n",
        "# === Retrain the model on all data ===\n",
        "_, trained_model = train_spectransformer(\n",
        "    model=model,\n",
        "    train_loader=train_all_loader,\n",
        "    val_loader=None,\n",
        "    epochs=TEST_EPOCHS,\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    lr_scheduler_patience=LR_SCHEDULER_PATIENCE,\n",
        "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
        "    weight_decay=best_params[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "\n",
        "# === Variety test ===\n",
        "df_results_variety, rmse_variety, r2_variety, acc_variety = test_spectransformer(\n",
        "    trained_model=trained_model,\n",
        "    test_loader=test_loader_variety\n",
        ")\n",
        "\n",
        "# === Season test ===\n",
        "df_results_season, rmse_season, r2_season, acc_season = test_spectransformer(\n",
        "    trained_model=trained_model,\n",
        "    test_loader=test_loader_season\n",
        ")\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Test Set\": [\"Variety\", \"Season\"],\n",
        "    \"RMSE\": [rmse_variety, rmse_season],\n",
        "    \"R²\": [r2_variety, r2_season],\n",
        "    \"% Within 20%\": [acc_variety, acc_season]\n",
        "})\n",
        "\n",
        "print(summary)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491950710
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Inference Time Analysis_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_sample_set(\n",
        "    df_variety: pd.DataFrame,\n",
        "    df_season: pd.DataFrame,\n",
        "    random_state: int,\n",
        "    sample_size: int = 1000\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Combine two test sets (variety and season), sample rows randomly, and return X and y arrays.\n",
        "\n",
        "    Parameters:\n",
        "        df_variety   : DataFrame for variety-based test set\n",
        "        df_season    : DataFrame for season-based test set\n",
        "        random_state : Random seed for reproducibility\n",
        "        sample_size  : Number of rows to sample from combined test set\n",
        "\n",
        "    Returns:\n",
        "        x_sample : NumPy array of shape (sample_size, n_features) with spectral features\n",
        "        y_sample : NumPy array of shape (sample_size,) with corresponding Brix values\n",
        "    \"\"\"\n",
        "    # Combine the two test sets\n",
        "    df_combined = pd.concat([df_variety, df_season], axis=0)\n",
        "\n",
        "    # Randomly sample rows from the combined test set\n",
        "    df_sample = df_combined.sample(\n",
        "        n=sample_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Split into X and y arrays\n",
        "    x_sample, y_sample = split_x_y(df_sample)\n",
        "\n",
        "    return x_sample, y_sample\n",
        "\n",
        "def test_spectransformer_inference_time(\n",
        "    model: nn.Module,\n",
        "    x_test: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Measure average one-by-one inference time of a SpectraTransformer model in milliseconds.\n",
        "\n",
        "    Parameters:\n",
        "        model   : Trained SpectraTransformer model\n",
        "        x_test  : Test feature matrix of shape (n_samples, n_spectral_features)\n",
        "\n",
        "    Returns:\n",
        "        avg_inference_time_ms : Average inference time per sample in milliseconds\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    times = []\n",
        "\n",
        "    # Convert numpy array to the expected tensor format for ViT\n",
        "    # x_test shape: (n_samples, n_spectral_features)\n",
        "    # Need to convert to: (1, 1, n_spectral_features, 1) for each sample\n",
        "    \n",
        "    for x in x_test:\n",
        "        # Convert single sample to tensor with proper shape for ViT\n",
        "        x_input = torch.from_numpy(x).float().unsqueeze(0).unsqueeze(0).unsqueeze(-1)  # Shape: (1, 1, n_features, 1)\n",
        "        x_input = x_input.to(device)\n",
        "        \n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            _ = model(x_input).cpu().numpy().flatten()[0]\n",
        "        end = time.time()\n",
        "        \n",
        "        times.append(end - start)\n",
        "\n",
        "    avg_inference_time_ms = np.mean(times) * 1000\n",
        "    print(f\"Average inference time: {avg_inference_time_ms:.3f} ms/sample\")\n",
        "\n",
        "    return avg_inference_time_ms"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491957020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Create sample set for inference time measurement ===\n",
        "x_inference_time, y_inference_time = get_inference_sample_set(\n",
        "    df_test_variety,\n",
        "    df_test_season,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# === Compute the average inference time ===\n",
        "inference_time = test_spectransformer_inference_time(\n",
        "    trained_model, \n",
        "    x_inference_time\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1754491965654
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}